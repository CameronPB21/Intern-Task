{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "NORMAL = 0\n",
    "INTERICTAL = 1\n",
    "ICTAL = 2\n",
    "\n",
    "# Creating file_list for data\n",
    "data_path = \"C:\\\\Users\\\\camer\\\\Desktop\\\\Neurovigil\\\\EEG_Data\\\\\"\n",
    "folder_names = ['Z_normal', 'O_normal', 'N_interictal', \n",
    "                'F_interictal', 'S_ictal']\n",
    "state_label = [NORMAL]*200 + [INTERICTAL]*200 + [ICTAL]*100\n",
    "label_list = [data_path + \"Z_normal\" + \"\\\\*.txt\",\n",
    "             data_path + \"O_normal\" + \"\\\\*.txt\",\n",
    "             data_path + \"N_interictal\" + \"\\\\*.txt\",\n",
    "             data_path + \"F_interictal\" + \"\\\\*.txt\",\n",
    "             data_path + \"S_ictal\" + \"\\\\*.txt\"]\n",
    "file_list = []\n",
    "for label in label_list:\n",
    "    file_list += glob.glob(label)\n",
    "    \n",
    "# Pulling data\n",
    "data = [[]]*500\n",
    "i = 0\n",
    "for file in file_list:\n",
    "    arr = open(file).read()\n",
    "    data[i] = ([int(x) for x in arr.split()])\n",
    "    i += 1\n",
    "data = np.array(data)\n",
    "data_transpose = np.transpose(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable/data organization\n",
    "x = data\n",
    "y = state_label\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PCA to first decide where %95 of the data is, then fit to that %95\n",
    "def my_preprocessing(data):\n",
    "    data = preprocessing.scale(data)\n",
    "    pca1 = decomposition.PCA()\n",
    "    pca1.fit(data)\n",
    "    minimum_data = 0\n",
    "    components = 0\n",
    "    for i in pca1.explained_variance_ratio_:\n",
    "        minimum_data += i\n",
    "        components += 1\n",
    "        if minimum_data > 0.95:\n",
    "            print(\"minimum_data = \" + str(minimum_data) + \"\\nafter x components:\" + str(components))\n",
    "            break\n",
    "    pca = decomposition.PCA(n_components = components)\n",
    "    data = pca.fit_transform(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create, train, test an SVC Model\n",
    "def svc_model(x_train, y_train, x_test, y_test):\n",
    "    classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True))\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_test_preds = classifier.predict(x_test)\n",
    "\n",
    "    fpr, tpr, roc_auc = roc_auc_calc(n_classes, y_test, y_test_preds)\n",
    "    plot_roc(fpr, tpr, roc_auc, 'Receiver Operating Characteristic: SVC Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create, train, test a Decision Tree Model\n",
    "def decision_tree_model(x_train, y_train, x_test, y_test, iterations=1):\n",
    "    decision_tree = DecisionTreeClassifier(random_state=0)\n",
    "    for _ in range(iterations):\n",
    "        decision_tree.fit(x_train, y_train)\n",
    "        importances = decision_tree.feature_importances_\n",
    "        y_test_preds = decision_tree.predict(x_test)  \n",
    "        fpr, tpr, roc_auc = roc_auc_calc(n_classes, y_test, y_test_preds)\n",
    "        predictions = decision_tree.predict(x_test)\n",
    "    plot_roc(fpr, tpr, roc_auc, 'Receiver Operating Characteristic: Decision Tree Model')\n",
    "    return importances, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for a general model\n",
    "def roc_auc_calc(n_classes, y_test, y_test_preds):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_test_preds[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    return fpr, tpr, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an ROC curve\n",
    "def plot_roc(fpr, tpr, roc_auc, graph_title):\n",
    "    #Plotting ROC curve for SVC Model\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[2], tpr[2], color='red',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(graph_title)\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-66b94fc489a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_preprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimportances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecision_tree_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'my_preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "data = my_preprocessing(data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, y, test_size=0.1, random_state=1)\n",
    "importances, predictions = decision_tree_model(x_train, y_train, x_test, y_test, )\n",
    "\n",
    "\n",
    "#for i in range(4):\n",
    "#    deleted = 0\n",
    "#    new_y = y\n",
    "#    new_data = data\n",
    "#    for i in range(np.size(importances)):\n",
    "#        if importances[i] == 0:\n",
    "#            new_data = np.delete(new_data, i - deleted, 1)\n",
    "#            new_y = np.delete(new_y, i - deleted, 0)\n",
    "#            deleted += 1\n",
    "#    \n",
    "#    new_data = my_preprocessing(new_data)\n",
    "#    x_train, x_test, y_train, y_test = train_test_split(data, y, test_size=.2, random_state=1)\n",
    "#    importances, predictions = decision_tree_model(x_train, y_train, x_test, y_test, )\n",
    "#    print(np.size(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
